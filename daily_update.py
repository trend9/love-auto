import os
import json
import re
import hashlib
from datetime import datetime
from llama_cpp import Llama

# =========================
# Paths
# =========================

MODEL_PATH = "./models/model.gguf"

QUESTIONS_PATH = "data/questions.json"
USED_PATH = "data/used_questions.json"

POST_TEMPLATE_PATH = "post_template.html"
POST_DIR = "posts"
SITE_URL = "https://trend9.github.io/love-auto"

MAX_CONTEXT = 4096
MAX_RETRY = 5

# =========================
# LLMï¼ˆsingle-process / 1å›ãƒ­ãƒ¼ãƒ‰ï¼‰
# =========================

llm = Llama(
    model_path=MODEL_PATH,
    n_ctx=MAX_CONTEXT,
    temperature=0.85,
    top_p=0.9,
    repeat_penalty=1.15,
    verbose=False,
)

# =========================
# Utils
# =========================

def load_json(path, default):
    if not os.path.exists(path):
        return default
    try:
        with open(path, encoding="utf-8") as f:
            return json.load(f)
    except:
        return default

def save_json(path, data):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def save_text(path, text):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        f.write(text)

def esc(t: str) -> str:
    return (
        t.replace("&", "&amp;")
         .replace("<", "&lt;")
         .replace(">", "&gt;")
         .replace('"', "&quot;")
    )

def today():
    now = datetime.now()
    return {
        "iso": now.isoformat(),
        "jp": now.strftime("%Yå¹´%mæœˆ%dæ—¥")
    }

def uid():
    return datetime.now().strftime("%Y%m%d_%H%M%S_%f")

def slugify_jp(text):
    text = re.sub(r"[^\wã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]", "", text)
    return text[:60]

def normalize(t):
    return "".join(t.split()).lower()

def content_hash(title, body):
    return hashlib.sha256((normalize(title) + normalize(body)).encode()).hexdigest()

# =========================
# Question Generateï¼ˆçµ¶å¯¾ã«è½ã¡ãªã„æœ€çµ‚ç‰ˆï¼‰
# =========================

def generate_question():
    base_prompt = """
ã‚ãªãŸã¯ã€Œæ‹æ„›ãƒ»äººé–“é–¢ä¿‚ã®å®Ÿä½“é¨“ç›¸è«‡ã€ã‚’1ä»¶ã ã‘ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€å³å®ˆã€‘
ãƒ»æŠ½è±¡è«–ã€ãƒ†ãƒ³ãƒ—ãƒ¬ç¦æ­¢
ãƒ»å…·ä½“çš„ãªæœŸé–“ï¼é–¢ä¿‚æ€§ï¼å‡ºæ¥äº‹ã‚’å«ã‚ã‚‹
ãƒ»æ„Ÿæƒ…ã®è‘›è—¤ã‚’å¿…ãšå…¥ã‚Œã‚‹

ã€å½¢å¼ã€‘
ã‚¿ã‚¤ãƒˆãƒ«ï¼šã€‡ã€‡ã€‡
è³ªå•ï¼šã€‡ã€‡ã€‡
"""

    phases = [
        {"title": 20, "body": 120},  # ç†æƒ³
        {"title": 15, "body": 80},   # ç¾å®Ÿ
        {"title": 10, "body": 50},   # æœ€çµ‚ä¿é™º
    ]

    for phase in phases:
        for _ in range(MAX_RETRY):
            r = llm(base_prompt, max_tokens=700)
            text = r["choices"][0]["text"].strip()

            if "ã‚¿ã‚¤ãƒˆãƒ«ï¼š" not in text or "è³ªå•ï¼š" not in text:
                continue

            title = text.split("ã‚¿ã‚¤ãƒˆãƒ«ï¼š")[1].split("è³ªå•ï¼š")[0].strip()
            body = text.split("è³ªå•ï¼š")[1].strip()

            if len(title) >= phase["title"] and len(body) >= phase["body"]:
                return title, body

    # ğŸ”¥ ã“ã“ã«ã¯åŸºæœ¬æ¥ãªã„ãŒã€Actionsçµ¶å¯¾åœæ­¢é˜²æ­¢
    return (
        "ä»˜ãåˆã£ã¦3å¹´ã®å½¼ã¨ã®å°†æ¥ã«ä¸å®‰ã‚’æ„Ÿã˜å§‹ã‚ãŸç†ç”±",
        "ä»˜ãåˆã£ã¦3å¹´ã«ãªã‚‹å½¼ãŒã„ã¾ã™ã€‚æœ€è¿‘ã€çµå©šã‚„å°†æ¥ã®è©±ã‚’ã™ã‚‹ã¨è©±é¡Œã‚’å¤‰ãˆã‚‰ã‚Œã‚‹ã“ã¨ãŒå¢—ãˆã€ä¸å®‰ã‚’æ„Ÿã˜ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚å½¼ã®ã“ã¨ã¯å¥½ãã§ã™ãŒã€ã“ã®ã¾ã¾æ™‚é–“ã ã‘ãŒéãã¦ã„ãã®ã§ã¯ãªã„ã‹ã¨ç„¦ã£ã¦ã„ã¾ã™ã€‚ã©ã†å‘ãåˆãˆã°ã„ã„ã®ã‹åˆ†ã‹ã‚Šã¾ã›ã‚“ã€‚"
    )

# =========================
# Article Generateï¼ˆJSONå®Œå…¨ä¿è¨¼ï¼‰
# =========================

REQUIRED_FIELDS = {
    "lead": 80,
    "summary": 120,
    "psychology": 150,
    "actions": 3,
    "ng": 2,
    "misunderstanding": 100,
    "conclusion": 120
}

def generate_article_struct(question: str) -> dict:
    prompt = f"""
ã‚ãªãŸã¯æ‹æ„›ç›¸è«‡ã«ç­”ãˆã‚‹æ—¥æœ¬äººå¥³æ€§AIã€Œçµå§‰ã•ã‚“ã€ã§ã™ã€‚

ä»¥ä¸‹ã®JSONã‚’**å¿…ãšã™ã¹ã¦åŸ‹ã‚ã¦**å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
1ã¤ã§ã‚‚æ¬ ã‘ãŸã‚‰å¤±æ•—ã§ã™ã€‚

ã€å³å®ˆã€‘
ãƒ»JSONä»¥å¤–ã¯å‡ºåŠ›ã—ãªã„
ãƒ»èª¬æ•™ã—ãªã„ï¼æ–­å®šã—ãªã„
ãƒ»å…±æ„Ÿã¨å…·ä½“ä¾‹é‡è¦–

ã€JSONå½¢å¼ã€‘
{{
  "lead": "å°å…¥æ–‡ï¼ˆ80æ–‡å­—ä»¥ä¸Šï¼‰",
  "summary": "çµè«–ï¼ˆ120æ–‡å­—ä»¥ä¸Šï¼‰",
  "psychology": "ç›¸æ‰‹ã®å¿ƒç†è§£èª¬ï¼ˆ150æ–‡å­—ä»¥ä¸Šï¼‰",
  "actions": ["å…·ä½“è¡Œå‹•1", "å…·ä½“è¡Œå‹•2", "å…·ä½“è¡Œå‹•3"],
  "ng": ["é¿ã‘ãŸã„è¡Œå‹•1", "é¿ã‘ãŸã„è¡Œå‹•2"],
  "misunderstanding": "ã‚ˆãã‚ã‚‹èª¤è§£ï¼ˆ100æ–‡å­—ä»¥ä¸Šï¼‰",
  "conclusion": "ã¾ã¨ã‚ï¼ˆ120æ–‡å­—ä»¥ä¸Šï¼‰"
}}

ã€ç›¸è«‡å†…å®¹ã€‘
{question}
"""
    r = llm(prompt, max_tokens=2800)
    return json.loads(r["choices"][0]["text"].strip())

def validate_article(data: dict):
    for k, v in REQUIRED_FIELDS.items():
        if k not in data:
            raise ValueError(f"{k} æ¬ è½")
        if isinstance(v, int):
            if not isinstance(data[k], str) or len(data[k]) < v:
                raise ValueError(f"{k} çŸ­ã™ã")
        else:
            if not isinstance(data[k], list) or len(data[k]) < v:
                raise ValueError(f"{k} è¦ç´ ä¸è¶³")

# =========================
# Main
# =========================

def main():
    questions = load_json(QUESTIONS_PATH, [])
    used = load_json(USED_PATH, [])

    used_ids = {u["id"] for u in used}
    hashes = {q["content_hash"] for q in questions}

    # --- å¸¸ã«è³ªå•ã‚’ç”Ÿæˆ ---
    title, body = generate_question()
    h = content_hash(title, body)

    if h in hashes:
        print("â„¹ï¸ é‡è¤‡è³ªå•æ¤œçŸ¥ â†’ ã‚¹ã‚­ãƒƒãƒ—")
        return

    slug = slugify_jp(title)
    qid = uid()

    question = {
        "id": qid,
        "title": title,
        "slug": slug,
        "question": body,
        "created_at": today()["iso"],
        "content_hash": h,
        "url": f"posts/{slug}.html"
    }

    questions.append(question)
    save_json(QUESTIONS_PATH, questions)

    # --- è¨˜äº‹ç”Ÿæˆ ---
    article = None
    for i in range(MAX_RETRY):
        try:
            article = generate_article_struct(body)
            validate_article(article)
            break
        except Exception as e:
            print(f"âš ï¸ è¨˜äº‹å†ç”Ÿæˆ {i+1}/{MAX_RETRY}: {e}")

    if article is None:
        raise RuntimeError("è¨˜äº‹ç”Ÿæˆå¤±æ•—")

    with open(POST_TEMPLATE_PATH, encoding="utf-8") as f:
        tpl = f.read()

    today_info = today()

    html = (
        tpl.replace("{{TITLE}}", esc(title))
           .replace("{{META_DESCRIPTION}}", esc(body[:120]))
           .replace("{{DATE_ISO}}", today_info["iso"])
           .replace("{{DATE_JP}}", today_info["jp"])
           .replace("{{PAGE_URL}}", f"{SITE_URL}/posts/{slug}.html")
           .replace("{{LEAD}}", esc(article["lead"]))
           .replace("{{QUESTION}}", esc(body))
           .replace("{{SUMMARY_ANSWER}}", esc(article["summary"]))
           .replace("{{PSYCHOLOGY}}", esc(article["psychology"]))
           .replace(
               "{{ACTION_LIST}}",
               "\n".join(f"<li>{esc(a)}</li>" for a in article["actions"])
           )
           .replace(
               "{{NG_LIST}}",
               "\n".join(f"<li>{esc(n)}</li>" for n in article["ng"])
           )
           .replace("{{MISUNDERSTANDING}}", esc(article["misunderstanding"]))
           .replace("{{CONCLUSION}}", esc(article["conclusion"]))
           .replace("{{RELATED}}", "")
           .replace("{{PREV}}", "")
           .replace("{{NEXT}}", "")
           .replace("{{CANONICAL}}", "")
           .replace("{{FAQ}}", "")
    )

    save_text(os.path.join(POST_DIR, f"{slug}.html"), html)

    used.append({"id": qid})
    save_json(USED_PATH, used)

    print("âœ… è¨˜äº‹ç”Ÿæˆå®Œäº†ï¼ˆsingle-process / çµ¶å¯¾åœæ­¢ã—ãªã„ï¼‰")

if __name__ == "__main__":
    main()
