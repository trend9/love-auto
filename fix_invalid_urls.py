#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸é©åˆ‡ãªURLï¼ˆæ—¥æœ¬èªã‚„ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ï¼‰ã‚’æ¤œå‡ºã—ã€
å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«åŸºã¥ã„ã¦æ­£ã—ã„URLã«ä¿®æ­£ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹å–„ç‰ˆï¼‰
"""

import os
import re
from pathlib import Path
from urllib.parse import quote, unquote

# å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
POSTS_DIR = "posts"
BASE_URL = "https://yui-love.vercel.app/posts/"

def get_actual_filename_map():
    """postsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å®Ÿéš›ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«åã‚’ãƒãƒƒãƒ”ãƒ³ã‚°"""
    posts_path = Path(POSTS_DIR)
    actual_files = {}
    
    for html_file in posts_path.glob("*.html"):
        filename = html_file.name
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚­ãƒ¼ã¨ã—ã¦ä¿å­˜
        actual_files[filename] = filename
        # URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸå½¢ã‚‚ã‚­ãƒ¼ã«è¿½åŠ 
        encoded = quote(filename, safe='')
        actual_files[encoded] = filename
        
    return actual_files

def extract_filename_from_url(url):
    """URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åéƒ¨åˆ†ã‚’æŠ½å‡º"""
    # https://yui-love.vercel.app/posts/xxxxx.html ã‹ã‚‰ xxxxx.html ã‚’å–å¾—
    match = re.search(r'/posts/([^"]+\.html)', url)
    if match:
        return match.group(1)
    return None

def find_correct_filename(incorrect_filename, actual_files, current_file=None):
    """
    ä¸é©åˆ‡ãªãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ­£ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ¨æ¸¬
    ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä½¿ç”¨
    """
    # URLãƒ‡ã‚³ãƒ¼ãƒ‰
    decoded = unquote(incorrect_filename)
    
    # æ—¢ã«æ­£ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åã®å ´åˆ
    if decoded in actual_files:
        return actual_files[decoded]
    
    # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«è‡ªèº«ã‚’æŒ‡ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯
    if current_file and current_file in actual_files.values():
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º
        current_date = re.search(r'(\d{8})', current_file)
        incorrect_date = re.search(r'(\d{8})', decoded)
        
        if current_date and incorrect_date and current_date.group(1) == incorrect_date.group(1):
            # åŒã˜æ—¥ä»˜ãªã‚‰ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«è‡ªèº«ã‚’è¿”ã™
            return current_file
    
    # æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºï¼ˆ20260101å½¢å¼ï¼‰
    date_match = re.search(r'(\d{8})', decoded)
    if not date_match:
        return None
    
    date_str = date_match.group(1)
    
    # åŒã˜æ—¥ä»˜ã‚’æŒã¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    for actual_file in actual_files.values():
        if date_str in actual_file:
            return actual_file
    
    return None

def fix_urls_in_file(filepath, actual_files):
    """1ã¤ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ä¸é©åˆ‡ãªURLã‚’ä¿®æ­£"""
    current_filename = Path(filepath).name
    
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    original_content = content
    changes = []
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: href="xxxxx.html" (ç›¸å¯¾ãƒ‘ã‚¹)
    def replace_href(match):
        full_match = match.group(0)
        url = match.group(1)
        
        # ASCIIæ–‡å­—ã®ã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if url.isascii() and not any(char in url for char in ['%', 'ãƒ»', 'ï¼ˆ', 'ï¼‰']):
            return full_match
        
        filename = url.split('/')[-1]
        correct = find_correct_filename(filename, actual_files, current_filename)
        
        if correct and correct != filename:
            changes.append(f"  {filename} â†’ {correct}")
            return f'href="{correct}"'
        return full_match
    
    content = re.sub(r'href="([^"]+\.html)"', replace_href, content)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: content="https://yui-love.vercel.app/posts/xxxxx.html" (çµ¶å¯¾ãƒ‘ã‚¹)
    def replace_content_url(match):
        full_match = match.group(0)
        url = match.group(1)
        
        filename = extract_filename_from_url(url)
        if not filename:
            return full_match
        
        # ASCIIæ–‡å­—ã®ã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if filename.isascii() and not any(char in filename for char in ['%', 'ãƒ»', 'ï¼ˆ', 'ï¼‰']):
            return full_match
        
        correct = find_correct_filename(filename, actual_files, current_filename)
        
        if correct and correct != filename:
            new_url = BASE_URL + correct
            changes.append(f"  {url} â†’ {new_url}")
            return f'content="{new_url}"'
        return full_match
    
    content = re.sub(r'content="(https://yui-love\.vercel\.app/posts/[^"]+\.html)"', replace_content_url, content)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: @id in JSON-LD
    def replace_jsonld_id(match):
        full_match = match.group(0)
        url = match.group(1)
        
        filename = extract_filename_from_url(url)
        if not filename:
            return full_match
        
        # ASCIIæ–‡å­—ã®ã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if filename.isascii() and not any(char in filename for char in ['%', 'ãƒ»', 'ï¼ˆ', 'ï¼‰']):
            return full_match
        
        correct = find_correct_filename(filename, actual_files, current_filename)
        
        if correct and correct != filename:
            new_url = BASE_URL + correct
            changes.append(f"  {url} â†’ {new_url}")
            return f'"@id": "{new_url}"'
        return full_match
    
    content = re.sub(r'"@id":\s*"(https://yui-love\.vercel\.app/posts/[^"]+\.html)"', replace_jsonld_id, content)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³4: rel="canonical" href="xxxxx.html" (ç›¸å¯¾ãƒ‘ã‚¹)
    def replace_canonical(match):
        full_match = match.group(0)
        url = match.group(1)
        
        # ASCIIæ–‡å­—ã®ã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if url.isascii() and not any(char in url for char in ['%', 'ãƒ»', 'ï¼ˆ', 'ï¼‰']):
            return full_match
        
        filename = url.split('/')[-1]
        correct = find_correct_filename(filename, actual_files, current_filename)
        
        if correct and correct != filename:
            changes.append(f"  canonical: {filename} â†’ {correct}")
            return f'<link rel="canonical" href="{BASE_URL}{correct}">'
        return full_match
    
    content = re.sub(r'<link rel="canonical" href="([^"]+\.html)">', replace_canonical, content)
    
    # å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
    if content != original_content:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        return changes
    
    return []

def main():
    print("ğŸ” ä¸é©åˆ‡ãªURLã®æ¤œå‡ºã¨ä¿®æ­£ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆæ”¹å–„ç‰ˆï¼‰...")
    print()
    
    # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åãƒãƒƒãƒ—ã‚’ä½œæˆ
    actual_files = get_actual_filename_map()
    print(f"âœ… {len(actual_files)} å€‹ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
    print()
    
    # postsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    posts_path = Path(POSTS_DIR)
    total_files = 0
    fixed_files = 0
    total_changes = 0
    
    for html_file in sorted(posts_path.glob("*.html")):
        total_files += 1
        changes = fix_urls_in_file(html_file, actual_files)
        
        if changes:
            fixed_files += 1
            total_changes += len(changes)
            print(f"ğŸ“ {html_file.name}")
            for change in changes:
                print(change)
            print()
    
    print("=" * 60)
    print(f"âœ… å‡¦ç†å®Œäº†")
    print(f"   å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {total_files} ä»¶")
    print(f"   ä¿®æ­£ãƒ•ã‚¡ã‚¤ãƒ«: {fixed_files} ä»¶")
    print(f"   ä¿®æ­£ç®‡æ‰€: {total_changes} ç®‡æ‰€")
    print("=" * 60)

if __name__ == "__main__":
    main()
